package benchmark

import (
	"bytes"
	"fmt"
	"os"
	"path/filepath"

	"github.com/shaban/ffire/pkg/fixture"
	"github.com/shaban/ffire/pkg/generator"
	"github.com/shaban/ffire/pkg/schema"
)

// GeneratePython generates a Python benchmark with embedded fixture
func GeneratePython(schema *schema.Schema, schemaName, messageName string, jsonData []byte, outputDir string, iterations int) error {
	if err := os.MkdirAll(outputDir, 0755); err != nil {
		return fmt.Errorf("failed to create output directory: %w", err)
	}

	// Step 1: Generate the Python package
	config := &generator.PackageConfig{
		Schema:    schema,
		Language:  "python",
		OutputDir: outputDir,
		Namespace: schemaName,
		Optimize:  2,
		Platform:  "current",
		Arch:      "current",
		NoCompile: false,
		Verbose:   false,
	}

	if err := generator.GeneratePackage(config); err != nil {
		return fmt.Errorf("failed to generate Python package: %w", err)
	}

	// Step 2: Convert JSON to binary fixture using the generated code
	binaryData, err := fixture.Convert(schema, messageName, jsonData)
	if err != nil {
		return fmt.Errorf("failed to convert JSON to binary: %w", err)
	}

	// Step 3: Write the binary fixture
	fixturePath := filepath.Join(outputDir, "python", "fixture.bin")
	if err := os.WriteFile(fixturePath, binaryData, 0644); err != nil {
		return fmt.Errorf("failed to write fixture: %w", err)
	}

	// Step 4: Generate the benchmark harness
	benchmarkCode := generatePythonBenchmarkCode(schemaName, messageName, iterations)
	benchPath := filepath.Join(outputDir, "python", "bench.py")
	if err := os.WriteFile(benchPath, []byte(benchmarkCode), 0644); err != nil {
		return fmt.Errorf("failed to write benchmark: %w", err)
	}

	// Step 5: Generate a run script for convenience
	runScript := generatePythonRunScript()
	runPath := filepath.Join(outputDir, "python", "run.sh")
	if err := os.WriteFile(runPath, []byte(runScript), 0755); err != nil {
		return fmt.Errorf("failed to write run script: %w", err)
	}

	return nil
}

// generatePythonBenchmarkCode generates the benchmark harness code
func generatePythonBenchmarkCode(schemaName, messageName string, iterations int) string {
	buf := &bytes.Buffer{}

	fmt.Fprintf(buf, `#!/usr/bin/env python3
"""
Benchmark for %s using ffire Python bindings.
Generated by ffire benchmark tool.
"""

import sys
from pathlib import Path

# Python automatically adds script directory to sys.path[0]
# For schemas named after builtin modules (e.g., 'struct'), this causes import conflicts
# Temporarily remove script dir from path while importing stdlib modules
script_dir = str(Path(__file__).parent)
original_path0 = sys.path[0] if sys.path else None
if sys.path and sys.path[0] == script_dir:
    sys.path.pop(0)

# Now safe to import stdlib modules
import time
import json
import os
import ctypes
import importlib.util

# Import our package using absolute file path to avoid conflicts
pkg_init = Path(__file__).parent / '%s' / '__init__.py'
spec = importlib.util.spec_from_file_location('ffire_generated_pkg', pkg_init)
pkg = importlib.util.module_from_spec(spec)
sys.modules['ffire_generated_pkg'] = pkg
spec.loader.exec_module(pkg)
Message = pkg.Message

# Restore original sys.path for any future imports
if original_path0 is not None and (not sys.path or sys.path[0] != original_path0):
    sys.path.insert(0, original_path0)

def main():
    # Load fixture
    fixture_path = Path(__file__).parent / 'fixture.bin'
    with open(fixture_path, 'rb') as f:
        fixture_data = f.read()
    
    iterations = %d
    json_output = os.getenv('BENCH_JSON') == '1'
    
    # Warmup
    for _ in range(1000):
        msg = Message.decode(fixture_data)
        encoded = msg.encode()
    
    # Benchmark decode
    start = time.perf_counter()
    for _ in range(iterations):
        msg = Message.decode(fixture_data)
    end = time.perf_counter()
    decode_time = end - start
    
    # Benchmark encode (decode once, then encode many times)
    msg = Message.decode(fixture_data)
    start = time.perf_counter()
    encoded = None
    for _ in range(iterations):
        encoded = msg.encode()
    end = time.perf_counter()
    encode_time = end - start
    
    # Calculate metrics
    encode_ns = int((encode_time / iterations) * 1e9)
    decode_ns = int((decode_time / iterations) * 1e9)
    total_ns = encode_ns + decode_ns
    
    if json_output:
        # Output JSON for automation
        result = {
            "language": "Python",
            "format": "ffire",
            "message": "%s",
            "iterations": iterations,
            "encode_ns": encode_ns,
            "decode_ns": decode_ns,
            "total_ns": total_ns,
            "wire_size": len(encoded),
            "fixture_size": len(fixture_data),
            "timestamp": time.strftime("%%Y-%%m-%%dT%%H:%%M:%%S%%z")
        }
        print(json.dumps(result))
    else:
        # Print human-readable results
        print(f"ffire benchmark: %s")
        print(f"Iterations:  {iterations}")
        print(f"Encode:      {encode_ns} ns/op")
        print(f"Decode:      {decode_ns} ns/op")
        print(f"Total:       {total_ns} ns/op")
        print(f"Wire size:   {len(encoded)} bytes")
        print(f"Fixture:     {len(fixture_data)} bytes")
        print(f"Total time:  {(encode_time + decode_time):.2f}s")

if __name__ == '__main__':
    main()
`, schemaName, schemaName, iterations, schemaName, schemaName)

	return buf.String()
}

// generatePythonRunScript generates a convenience run script
func generatePythonRunScript() string {
	return `#!/bin/bash
# Convenience script to run Python benchmark

# Check if python3 is available
if ! command -v python3 &> /dev/null; then
    echo "Error: python3 not found"
    exit 1
fi

# Set PYTHONPATH to include the current directory
export PYTHONPATH="$(pwd):$PYTHONPATH"

# Run benchmark
python3 bench.py "$@"
`
}
